
epoch: 1
step: 100, loss: 1.364661693572998
step: 200, loss: 0.7332220077514648
step: 300, loss: 0.43361809849739075
per: 0.1351

epoch: 2
step: 100, loss: 0.34102684259414673
step: 200, loss: 0.2544928193092346
step: 300, loss: 0.2195805311203003
per: 0.0844

epoch: 3
step: 100, loss: 0.1753307729959488
step: 200, loss: 0.16198480129241943
step: 300, loss: 0.15773659944534302
per: 0.0591

epoch: 4
step: 100, loss: 0.12869387865066528
step: 200, loss: 0.11094560474157333
step: 300, loss: 0.1355227828025818
per: 0.0520

epoch: 5
step: 100, loss: 0.10664228349924088
step: 200, loss: 0.11128806322813034
step: 300, loss: 0.09142374247312546
per: 0.0472

epoch: 6
step: 100, loss: 0.08016639947891235
step: 200, loss: 0.07575495541095734
step: 300, loss: 0.08113332837820053
per: 0.0442

epoch: 7
step: 100, loss: 0.08871763199567795
step: 200, loss: 0.08524780720472336
step: 300, loss: 0.07057054340839386
per: 0.0428

epoch: 8
step: 100, loss: 0.04839188978075981
step: 200, loss: 0.0498611144721508
step: 300, loss: 0.05599088594317436
per: 0.0426

epoch: 9
step: 100, loss: 0.06250421702861786
step: 200, loss: 0.062004826962947845
step: 300, loss: 0.05700404569506645
per: 0.0411

epoch: 10
step: 100, loss: 0.0449235774576664
step: 200, loss: 0.053563687950372696
step: 300, loss: 0.04616847634315491
per: 0.0381

epoch: 11
step: 100, loss: 0.03940886631608009
step: 200, loss: 0.048379216343164444
step: 300, loss: 0.04919739067554474
per: 0.0379

epoch: 12
step: 100, loss: 0.04554266482591629
step: 200, loss: 0.043632686138153076
step: 300, loss: 0.0581946074962616
per: 0.0395

epoch: 13
step: 100, loss: 0.029790343716740608
step: 200, loss: 0.043222542852163315
step: 300, loss: 0.039117950946092606
per: 0.0379

epoch: 14
step: 100, loss: 0.04102986678481102
step: 200, loss: 0.04372571036219597
step: 300, loss: 0.04538340121507645
per: 0.0385

epoch: 15
step: 100, loss: 0.027253972366452217
step: 200, loss: 0.0327860452234745
step: 300, loss: 0.024615174159407616
per: 0.0357

epoch: 16
step: 100, loss: 0.04091867804527283
step: 200, loss: 0.033419251441955566
step: 300, loss: 0.0419791080057621
per: 0.0373

epoch: 17
step: 100, loss: 0.019990364089608192
step: 200, loss: 0.02425040863454342
step: 300, loss: 0.035175543278455734
per: 0.0378

epoch: 18
step: 100, loss: 0.0310219693928957
step: 200, loss: 0.03484885394573212
step: 300, loss: 0.03835645690560341
per: 0.0384

epoch: 19
step: 100, loss: 0.0346144363284111
step: 200, loss: 0.01760477013885975
step: 300, loss: 0.022949015721678734
per: 0.0362

epoch: 20
step: 100, loss: 0.023063616827130318
step: 200, loss: 0.02177491784095764
step: 300, loss: 0.030533913522958755
per: 0.0370

epoch: 21
step: 100, loss: 0.0256224162876606
step: 200, loss: 0.027316804975271225
step: 300, loss: 0.029633279889822006
per: 0.0364

epoch: 22
step: 100, loss: 0.02184160426259041
step: 200, loss: 0.03327885642647743
step: 300, loss: 0.03172747418284416
per: 0.0360

epoch: 23
step: 100, loss: 0.02108975313603878
step: 200, loss: 0.02697446197271347
step: 300, loss: 0.024688657373189926
per: 0.0387

epoch: 24
step: 100, loss: 0.03147834911942482
step: 200, loss: 0.029155820608139038
step: 300, loss: 0.03043999895453453
per: 0.0373

epoch: 25
step: 100, loss: 0.02266409806907177
step: 200, loss: 0.02281046286225319
step: 300, loss: 0.031092386692762375
per: 0.0361

epoch: 26
step: 100, loss: 0.023577095940709114
step: 200, loss: 0.0336429700255394
step: 300, loss: 0.03212148696184158
per: 0.0369

epoch: 27
step: 100, loss: 0.02310544066131115
step: 200, loss: 0.03341269865632057
step: 300, loss: 0.02545672282576561
per: 0.0373

epoch: 28
step: 100, loss: 0.016860736533999443
step: 200, loss: 0.02674241177737713
step: 300, loss: 0.03611106798052788
per: 0.0382

epoch: 29
step: 100, loss: 0.018738094717264175
step: 200, loss: 0.0169849656522274
step: 300, loss: 0.026017839089035988
per: 0.0378

epoch: 30
step: 100, loss: 0.02669721283018589
step: 200, loss: 0.025722019374370575
step: 300, loss: 0.03726130351424217
per: 0.0371

epoch: 31
step: 100, loss: 0.024938229471445084
step: 200, loss: 0.02273925393819809
step: 300, loss: 0.026346514001488686
per: 0.0367

epoch: 32
step: 100, loss: 0.014214415103197098
step: 200, loss: 0.019668176770210266
step: 300, loss: 0.024090202525258064
per: 0.0362

epoch: 33
step: 100, loss: 0.01601230353116989
step: 200, loss: 0.01744723692536354
step: 300, loss: 0.020237812772393227
per: 0.0360

epoch: 34
step: 100, loss: 0.014483298175036907
step: 200, loss: 0.016628261655569077
step: 300, loss: 0.037567682564258575
per: 0.0370

epoch: 35
step: 100, loss: 0.022139206528663635
step: 200, loss: 0.015059747733175755
step: 300, loss: 0.017404314130544662
per: 0.0366

epoch: 36
step: 100, loss: 0.01649726927280426
step: 200, loss: 0.021844355389475822
step: 300, loss: 0.018800314515829086
per: 0.0369

epoch: 37
step: 100, loss: 0.021479353308677673
step: 200, loss: 0.023322410881519318
step: 300, loss: 0.022778596729040146
per: 0.0363

epoch: 38
step: 100, loss: 0.018712200224399567
step: 200, loss: 0.025357430800795555
step: 300, loss: 0.020663976669311523
per: 0.0368

epoch: 39
step: 100, loss: 0.019700447097420692
step: 200, loss: 0.017713727429509163
step: 300, loss: 0.027633020654320717
per: 0.0362

epoch: 40
step: 100, loss: 0.0176259595900774
step: 200, loss: 0.018484672531485558
step: 300, loss: 0.019535185769200325
per: 0.0372

epoch: 41
step: 100, loss: 0.020663168281316757
step: 200, loss: 0.015701068565249443
step: 300, loss: 0.02581717073917389
per: 0.0362

epoch: 42
step: 100, loss: 0.016858788207173347
step: 200, loss: 0.028168296441435814
step: 300, loss: 0.030969496816396713
per: 0.0385

epoch: 43
step: 100, loss: 0.016284482553601265
step: 200, loss: 0.012859166599810123
step: 300, loss: 0.022371364757418633
per: 0.0370

epoch: 44
step: 100, loss: 0.013793310150504112
step: 200, loss: 0.021229960024356842
step: 300, loss: 0.021608062088489532
per: 0.0359

epoch: 45
step: 100, loss: 0.022210827097296715
step: 200, loss: 0.01842542551457882
step: 300, loss: 0.02560296840965748
per: 0.0393

epoch: 46
step: 100, loss: 0.016496848315000534
step: 200, loss: 0.016977734863758087
step: 300, loss: 0.02295161411166191
per: 0.0369

epoch: 47
step: 100, loss: 0.020009059458971024
step: 200, loss: 0.029803941026329994
step: 300, loss: 0.015357314608991146
per: 0.0363

epoch: 48
step: 100, loss: 0.014839813113212585
step: 200, loss: 0.019502630457282066
step: 300, loss: 0.023924699053168297
per: 0.0368

epoch: 49
step: 100, loss: 0.013244793750345707
step: 200, loss: 0.02333630621433258
step: 300, loss: 0.024227838963270187
per: 0.0401

epoch: 50
step: 100, loss: 0.010348412208259106
step: 200, loss: 0.02131578139960766
step: 300, loss: 0.017095886170864105
per: 0.0369

epoch: 51
step: 100, loss: 0.018622461706399918
step: 200, loss: 0.015067336149513721
step: 300, loss: 0.020725486800074577
per: 0.0379

epoch: 52
step: 100, loss: 0.030162153765559196
step: 200, loss: 0.016513222828507423
step: 300, loss: 0.019009992480278015
per: 0.0368

epoch: 53
step: 100, loss: 0.012248994782567024
step: 200, loss: 0.019815396517515182
step: 300, loss: 0.0207222793251276
per: 0.0370

epoch: 54
step: 100, loss: 0.017759524285793304
step: 200, loss: 0.012025240808725357
step: 300, loss: 0.022925926372408867
per: 0.0367

epoch: 55
step: 100, loss: 0.011285620741546154
step: 200, loss: 0.015877727419137955
step: 300, loss: 0.01762198656797409
per: 0.0366

epoch: 56
step: 100, loss: 0.018709402531385422
step: 200, loss: 0.019229821860790253
step: 300, loss: 0.028593771159648895
per: 0.0377

epoch: 57
step: 100, loss: 0.014994649216532707
step: 200, loss: 0.032714858651161194
step: 300, loss: 0.020059822127223015
per: 0.0373

epoch: 58
step: 100, loss: 0.017620932310819626
step: 200, loss: 0.021685849875211716
step: 300, loss: 0.02350877970457077
per: 0.0369

epoch: 59
step: 100, loss: 0.01968533545732498
step: 200, loss: 0.020312925800681114
step: 300, loss: 0.019517531618475914
per: 0.0391

epoch: 60
step: 100, loss: 0.012944132089614868
step: 200, loss: 0.012165797874331474
step: 300, loss: 0.01392090693116188
per: 0.0366

epoch: 61
step: 100, loss: 0.014032765291631222
step: 200, loss: 0.019621996209025383
step: 300, loss: 0.02088959515094757
per: 0.0359

epoch: 62
step: 100, loss: 0.015573683194816113
step: 200, loss: 0.016678467392921448
step: 300, loss: 0.021501116454601288
per: 0.0370

epoch: 63
step: 100, loss: 0.017522504553198814
step: 200, loss: 0.015166210010647774
step: 300, loss: 0.02082500420510769
per: 0.0374

epoch: 64
step: 100, loss: 0.014752070419490337
step: 200, loss: 0.01690787263214588
step: 300, loss: 0.03685147687792778
per: 0.0383

epoch: 65
step: 100, loss: 0.013472379185259342
step: 200, loss: 0.018309546634554863
step: 300, loss: 0.017330100759863853
per: 0.0392

epoch: 66
step: 100, loss: 0.014952288009226322
step: 200, loss: 0.01706058531999588
step: 300, loss: 0.015126598067581654
per: 0.0377

epoch: 67
step: 100, loss: 0.01502526830881834
step: 200, loss: 0.018576567992568016
step: 300, loss: 0.024218305945396423
per: 0.0382

epoch: 68
step: 100, loss: 0.014251148328185081
step: 200, loss: 0.016311703249812126
step: 300, loss: 0.023493174463510513
per: 0.0373

epoch: 69
step: 100, loss: 0.016268761828541756
step: 200, loss: 0.017521580681204796
step: 300, loss: 0.016241412609815598
per: 0.0378

epoch: 70
step: 100, loss: 0.017161469906568527
step: 200, loss: 0.017737265676259995
step: 300, loss: 0.02277953363955021
per: 0.0371

epoch: 71
step: 100, loss: 0.022045738995075226
step: 200, loss: 0.018967315554618835
step: 300, loss: 0.016472594812512398
per: 0.0381

epoch: 72
step: 100, loss: 0.01451706700026989
step: 200, loss: 0.017193475738167763
step: 300, loss: 0.01987171173095703
per: 0.0372

epoch: 73
step: 100, loss: 0.017208188772201538
step: 200, loss: 0.011232231743633747
step: 300, loss: 0.021258490160107613
per: 0.0363

epoch: 74
step: 100, loss: 0.018222063779830933
step: 200, loss: 0.022529568523168564
step: 300, loss: 0.016654739156365395
per: 0.0372

epoch: 75
step: 100, loss: 0.012699193321168423
step: 200, loss: 0.008269712328910828
step: 300, loss: 0.021638093516230583
per: 0.0388

epoch: 76
step: 100, loss: 0.012873755767941475
step: 200, loss: 0.018510909751057625
step: 300, loss: 0.019841212779283524
per: 0.0375

epoch: 77
step: 100, loss: 0.01034468598663807
step: 200, loss: 0.018472302705049515
step: 300, loss: 0.0158747099339962
per: 0.0375

epoch: 78
step: 100, loss: 0.01619836501777172
step: 200, loss: 0.01664186827838421
step: 300, loss: 0.0169775802642107
per: 0.0372

epoch: 79
step: 100, loss: 0.015205102041363716
step: 200, loss: 0.02148149535059929
step: 300, loss: 0.021406179293990135
per: 0.0390

epoch: 80
step: 100, loss: 0.019639644771814346
step: 200, loss: 0.01726359687745571
step: 300, loss: 0.02687869407236576
per: 0.0376

epoch: 81
step: 100, loss: 0.00999218225479126
step: 200, loss: 0.011510631069540977
step: 300, loss: 0.031135817989706993
per: 0.0375

epoch: 82
step: 100, loss: 0.011017601005733013
step: 200, loss: 0.014528630301356316
step: 300, loss: 0.01689765974879265
per: 0.0370

epoch: 83
step: 100, loss: 0.008600709959864616
step: 200, loss: 0.02082972414791584
step: 300, loss: 0.017517700791358948
per: 0.0392

epoch: 84
step: 100, loss: 0.014978209510445595
step: 200, loss: 0.015851540490984917
step: 300, loss: 0.017130577936768532
per: 0.0382

epoch: 85
step: 100, loss: 0.014689777046442032
step: 200, loss: 0.023300863802433014
step: 300, loss: 0.026036961004137993
per: 0.0386

epoch: 86
step: 100, loss: 0.012294815853238106
step: 200, loss: 0.016513602808117867
step: 300, loss: 0.01924826391041279
per: 0.0385

epoch: 87
step: 100, loss: 0.019920455291867256
step: 200, loss: 0.01622396893799305
step: 300, loss: 0.021445652469992638
per: 0.0369

epoch: 88
step: 100, loss: 0.015724536031484604
step: 200, loss: 0.01991618424654007
step: 300, loss: 0.021155433729290962
per: 0.0380

epoch: 89
step: 100, loss: 0.007351988460868597
step: 200, loss: 0.010983898304402828
step: 300, loss: 0.017449328675866127
per: 0.0389

epoch: 90
step: 100, loss: 0.017427867278456688
step: 200, loss: 0.013348275795578957
step: 300, loss: 0.02142336405813694
per: 0.0383

epoch: 91
step: 100, loss: 0.010019080713391304
step: 200, loss: 0.020266786217689514
step: 300, loss: 0.025593159720301628
per: 0.0382

epoch: 92
step: 100, loss: 0.009561060927808285
step: 200, loss: 0.01490344014018774
step: 300, loss: 0.020303990691900253
per: 0.0398

epoch: 93
step: 100, loss: 0.017343154177069664
step: 200, loss: 0.018148383125662804
step: 300, loss: 0.02190643548965454
per: 0.0405

epoch: 94
step: 100, loss: 0.017209934070706367
step: 200, loss: 0.018802590668201447
step: 300, loss: 0.017224861308932304
per: 0.0380

epoch: 95
step: 100, loss: 0.017897672951221466
step: 200, loss: 0.016445955261588097
step: 300, loss: 0.02173968032002449
per: 0.0380

epoch: 96
step: 100, loss: 0.009982923977077007
step: 200, loss: 0.018381644040346146
step: 300, loss: 0.026704365387558937
per: 0.0377

epoch: 97
step: 100, loss: 0.013518488965928555
step: 200, loss: 0.02194628305733204
step: 300, loss: 0.018787233158946037
per: 0.0392

epoch: 98
step: 100, loss: 0.016435153782367706
step: 200, loss: 0.017943061888217926
step: 300, loss: 0.02140689454972744
per: 0.0391

epoch: 99
step: 100, loss: 0.014824911020696163
step: 200, loss: 0.02120613306760788
step: 300, loss: 0.018236609175801277
per: 0.0384

epoch: 100
step: 100, loss: 0.01862231455743313
step: 200, loss: 0.01876717247068882
step: 300, loss: 0.02579434961080551
per: 0.0379
per: 0.0379
target and output results for eval and test sets are saved in 'logs-run/result.txt' file.

Here are some samples for the test set:
['', 'ค ฺ ว า ม - ด ี - เ ย ี ่ ย ม', 'ค ฺ ว า ม - ด ี - เ ย ี ่ ย ม', '', 'ส ะ - ถ า น - ท ี ่ - ร ั บ - ช ำ - ร ะ', 'ส ะ - ถ า น - ท ี ่ - ร ั บ - ช ำ', '', 'ร ด - ช า ด - พ ื ้ น - ถ า น', 'ร ด - ช า ด - พ ื ้ น - ถ า น', '', 'บ ้ า น - ห ฺ น อ ง - ค ฺ ร อ ง', 'บ ้ า น - ห ฺ น อ ง - ค ฺ ร อ ง', '', 'น ก - เ ห ฺ ย ี ่ ย ว - แ ด ง', 'น ก - เ ห ฺ ย ี ่ ย ว - แ ด ง', '', 'เ ช ิ ง - ล บ', 'เ ช ิ ง - ล บ', '', 'ต ะ - ห ฺ ล า ด - ห ฺ ล ั ก - ซ ั บ - โ ต - เ ก ี ย ว', 'ต ะ - ห ฺ ล า ด - ห ฺ ล ั ก - ซ ั ก - โ ต - เ ก ี ย ว', '', 'ข ้ า ม - เ ร ื อ', 'ข ้ า ม - เ ร ื อ', '', 'ต ำ - บ น - ห ั ว - น า', 'ต ำ - บ น - ห ั ว - น า', '', 'ป ฺ ร า - ส า ด - พ ะ - น ม - ร ุ ้ ง', 'ป ฺ ร า - ส า ด - พ น - น ม - ร ุ ้ ง', '', 'บ ้ า น - ห ้ ว ย - ฮ ้ อ ม', 'บ ้ า น - ห ้ ว ย - ฮ ้ อ ม', '', 'ซ อ ย - พ ู ่ - ร ะ - ห ง', 'ซ อ ย - พ ู ่ - ร ะ - ห ง', '', 'ห ฺ น ว ด', 'ห ฺ น ว ด', '', 'ส ว น - ส ั ด - เ ป ิ ด', 'ส ว น - ส ั ด - เ ป ิ ด', '', 'บ ้ า น - เ ข า - ข ุ ย', 'บ ้ า น - เ ข า - ข ุ ย', '', 'จ ่ า - น ่ า - จ ด - ห ฺ ม า ย', 'จ ่ า - น ่ า - ด ่ - ห ฺ ม า ย', '', 'บ ้ า น - ห ฺ น อ ง - ข า - ห ฺ ย ั ่ ง', 'บ ้ า น - ห ฺ น อ ง - ข า - ห ฺ ย ั ่ ง', '', 'บ ั น - ช ี - ร า ย - ช ื ่ อ', 'บ ั น - ช ี - ร ื ย - ช ื ่ อ', '', 'ส ะ - ถ า - น ี - พ า ก - พ ื ้ น - ด ิ น - เ ค ฺ ล ื ่ อ น - ท ี ่', 'ส ะ - ถ า - น ี - พ า ก - พ ื ้ น - ช ิ น - เ ค ฺ ล ื ่ อ น - ท ี ่', '', 'ว ั น - ส ุ ก', 'ว ั น - ส ุ ก', '', 'น ก - ไ ฟ', 'น ก - ไ ฟ', '', 'ว อ น - เ ป - เ ป อ', 'ว อ น - เ ป อ เ ป อ', '', 'เ ม ื อ ง - ซ ั บ - โ ป ะ - โ ร ะ', 'เ ม ื อ ง - ป ั บ - โ ป ะ - ร ร ะ', '', 'ป ฺ ร ะ - เ ท ด - ฟ ิ - ล ิ บ - ป ิ น', 'ป ฺ ร ะ - เ ท ด - ฟ ิ - ล ิ บ - ป ิ น', '', 'บ ้ า น - แ ม ่ - ด ง', 'บ ้ า น - แ ม ่ - ด ง', '', 'ต ำ - บ น - ห ฺ น อ ง - ฉ ะ - ห ฺ ล อ ง', 'ต ำ - บ น - ห ฺ น อ ง - ฉ ะ - ห ฺ ล อ ง', '', 'ค ฺ ว า ม - ม ี - ช ี - ว ิ ด - ห ฺ ย ู ่', 'ค ฺ ว า ม - ม ี - ช ี - ว ิ ด - ห ฺ ย ู ่', '', 'บ ้ า น - ท ุ ่ ง - เ ข า - ส ะ - บ ้ า', 'บ ้ า น - ท ุ ่ ง - เ ข า - ส ะ - บ ้ า น', '', 'ก า น - ส ื ่ อ - ส า น - แ ห ่ ง - ป ฺ ร ะ - เ ท ด - ไ ท', 'ก า น - ส ื ่ อ - ส า น - แ ห ่ ง - ป ฺ ร ะ - เ ท ด - ไ ท', '', 'ต ำ - บ น - ห ั ว - เ ต ย', 'ต ำ - บ น - ห ั ว - เ ต ย', '', 'บ ้ า น - โ ป ฺ ร ่ ง - โ ก', 'บ ้ า น - โ ป ฺ ร ่ ง - โ ก', '', 'ต ้ น - ท ุ น - ผ ั น - แ ป ฺ ร', 'ต ้ น - ท ุ น - ผ ั น - แ ป ฺ ร', '', 'ช ั ้ น - ล อ ย', 'ช ั ้ น - ล อ ย', '']


Model's state_dict:
encoder.emb.weight 	 torch.Size([74, 256])
encoder.rnn.weight_ih_l0 	 torch.Size([1536, 256])
encoder.rnn.weight_hh_l0 	 torch.Size([1536, 512])
encoder.rnn.bias_ih_l0 	 torch.Size([1536])
encoder.rnn.bias_hh_l0 	 torch.Size([1536])
decoder.emb.weight 	 torch.Size([76, 256])
decoder.rnn.weight_ih_l0 	 torch.Size([1536, 256])
decoder.rnn.weight_hh_l0 	 torch.Size([1536, 512])
decoder.rnn.bias_ih_l0 	 torch.Size([1536])
decoder.rnn.bias_hh_l0 	 torch.Size([1536])
decoder.fc.weight 	 torch.Size([76, 512])
decoder.fc.bias 	 torch.Size([76])
per best : 0.0357
